# Qualidade do Ar em Alguns Estados Brasileiros

![Status do Projeto](https://img.shields.io/badge/Status-Em%20Desenvolvimento-blue)
![Python](https://img.shields.io/badge/Python-3.12%2B-blue?logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue?logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Ativo-blue?logo=docker&logoColor=white)
![LicenÃ§a](https://img.shields.io/badge/License-MIT-green)

## ğŸ¯ Sobre o Projeto

Este projeto nasceu da necessidade de demonstrar, com dados concretos, a correlaÃ§Ã£o entre a poluiÃ§Ã£o do ar em centros urbanos e a incidÃªncia de doenÃ§as respiratÃ³rias na populaÃ§Ã£o. Como consultora ambiental, o objetivo Ã© transformar dados brutos em visualizaÃ§Ãµes claras e impactantes, que possam ser utilizadas em campanhas de conscientizaÃ§Ã£o e na formulaÃ§Ã£o de polÃ­ticas pÃºblicas.

A anÃ¡lise cruza informaÃ§Ãµes histÃ³ricas sobre a **qualidade do ar**, obtidas atravÃ©s de fontes como o sistema **MonitorAr**, com dados de internaÃ§Ãµes e procedimentos relacionados a doenÃ§as respiratÃ³rias, disponibilizados pelo **DATASUS**.

## âœ¨ Objetivos Principais

-   **Coletar e Consolidar:** Agregar dados de diferentes fontes em um banco de dados estruturado e confiÃ¡vel.
-   **Analisar:** Identificar tendÃªncias, padrÃµes e correlaÃ§Ãµes estatÃ­sticas entre os nÃ­veis de poluentes e os registros de saÃºde.
-   **Visualizar:** Criar grÃ¡ficos e mapas interativos que facilitem a compreensÃ£o dos resultados por um pÃºblico nÃ£o tÃ©cnico.
-   **Disponibilizar:** Apresentar os _insights_ em um dashboard interativo, permitindo a exploraÃ§Ã£o dos dados por estado e por perÃ­odo.

## ğŸ”— Links importantes relacionados aos dados utilizados

-   [MonitorAr](https://dados.gov.br/dados/conjuntos-dados/ar-puro-monitorar)
-   [openDataSUS](https://opendatasus.saude.gov.br/dataset/srag-2021-a-2024)

## ğŸ› ï¸ Tecnologias Utilizadas

A arquitetura do projeto foi pensada para ser robusta, escalÃ¡vel e reprodutÃ­vel, utilizando as seguintes tecnologias:

| Tecnologia         | VersÃ£o/DescriÃ§Ã£o | PropÃ³sito na SoluÃ§Ã£o                                                              |
| :----------------- | :--------------- | :-------------------------------------------------------------------------------- |
| **PostgreSQL**     | `16-alpine`      | Banco de dados relacional para armazenamento seguro e estruturado.                |
| **Docker**         | `latest`         | ContainerizaÃ§Ã£o do banco de dados para garantir um ambiente consistente.          |
| **Python**         | `>=3.12`         | Linguagem principal para anÃ¡lise, processamento e visualizaÃ§Ã£o.                   |
| **Jupyter**        | `>=1.1.1`        | AnÃ¡lise exploratÃ³ria de dados (EDA) e prototipagem de modelos.                    |
| **Pandas**         | `>=2.3.1`        | ManipulaÃ§Ã£o, limpeza e estruturaÃ§Ã£o dos dados.                                    |
| **NumPy**          | `>=2.3.1`        | OperaÃ§Ãµes numÃ©ricas e cÃ¡lculos cientÃ­ficos.                                       |
| **Requests**       | `>=2.32.4`       | RealizaÃ§Ã£o de requisiÃ§Ãµes HTTP para coleta de dados de APIs externas.             |
| **psycopg**        | `>=3.2.9`        | Conector (cÃ³digo-fonte) para comunicaÃ§Ã£o entre a aplicaÃ§Ã£o Python e o PostgreSQL. |
| **psycopg-binary** | `>=3.2.9`        | Conector para comunicaÃ§Ã£o entre a aplicaÃ§Ã£o Python e o PostgreSQL.                |
| **dbt-postgres**   | `>=1.9.0`        | Ferramenta para transformaÃ§Ã£o de dados (ELT) no data warehouse.                   |
| **Matplotlib**     | `>=3.10.3`       | CriaÃ§Ã£o de grÃ¡ficos estÃ¡ticos e customizados.                                     |
| **Seaborn**        | `>=0.13.2`       | CriaÃ§Ã£o de grÃ¡ficos estatÃ­sticos e visualmente atraentes.                         |
| **Scikit-learn**   | `>=1.7.0`        | Modelagem estatÃ­stica e aplicaÃ§Ã£o de algoritmos de Machine Learning.              |
| **Streamlit**      | `>=1.46.1`       | ConstruÃ§Ã£o e deploy do dashboard interativo.                                      |
| **Pytest**         | `>=8.4.1`        | Testes automatizados para garantir a qualidade e a integridade do cÃ³digo.         |
| **python-dotenv**  | `>=1.1.1`        | Gerenciamento de variÃ¡veis de ambiente de forma segura.                           |

## ğŸ“‚ Estrutura do Projeto

**EM PROGRESSO**

```
.
â”œâ”€â”€ docker-compose.yml      # ğŸ³ Define e gerencia o serviÃ§o do banco de dados PostgreSQL.
â”‚
â”œâ”€â”€ notebooks/              # ğŸ““ Ambiente para anÃ¡lise de dados exploratÃ³ria e experimentaÃ§Ã£o.
â”‚   â””â”€â”€ 00_exemplo.ipynb
â”‚
â”œâ”€â”€ postgres_dw/            # ğŸ˜ DiretÃ³rio raiz do projeto dbt. Ã‰ aqui que o dbt vai operar.
â”‚   â”œâ”€â”€ analyses/           # <-- Para anÃ¡lises SQL que nÃ£o se tornam tabelas ou views (consultas ad-hoc).
â”‚   â”œâ”€â”€ dbt_project.yml     # <-- Configura o projeto, perfil e caminhos.
â”‚   â”œâ”€â”€ logs/               # <-- Pasta padrÃ£o onde o dbt salva os logs de execuÃ§Ã£o detalhados.
â”‚   â”‚   â””â”€â”€ dbt.log
â”‚   â”œâ”€â”€ macros/             # <-- Para criar funÃ§Ãµes reutilizÃ¡veis em Jinja/SQL.
â”‚   â”œâ”€â”€ models/             # âœ¨ DiretÃ³rio para os modelos SQL de transformaÃ§Ã£o (silver, gold).
â”‚   â”‚   â”œâ”€â”€ silver/            # ğŸ§¼ Camada 2: Limpeza, tipagem e renomeaÃ§Ã£o
â”‚   â”‚   â”‚   â””â”€â”€ silver_csv__exemplo.sql
â”‚   â”‚   â””â”€â”€ gold/               # ğŸ’ Camada 3: O Star Schema (tabelas Fatos e DimensÃµes)
â”‚   â”‚       â”œâ”€â”€ dim_exemplo.sql
â”‚   â”‚       â””â”€â”€ fatos_exemplo.sql
â”‚   â”œâ”€â”€ seeds/              # <-- Para carregar pequenos arquivos CSV no seu DW (ex: uma tabela de mapeamento de estados).
â”‚   â”œâ”€â”€ snapshots/          # <-- Para capturar mudanÃ§as em dados ao longo do tempo (SCD - Slowly Changing Dimensions).
â”‚   â”œâ”€â”€ target/             # ğŸ¯ Gerado pelo dbt.
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ tests/              # <-- Para testes de dados customizados do dbt.
â”‚
â”œâ”€â”€ pyproject.toml          # ğŸ Define as dependÃªncias do projeto Python para o 'uv'.
â”œâ”€â”€ README.md               # ğŸ“– A documentaÃ§Ã£o principal do seu projeto.
â”œâ”€â”€ src/                    # ğŸ‘¨â€ğŸ’» CÃ³digo-fonte Python para as etapas de ExtraÃ§Ã£o (E) e Carga (L).
â”‚   â”œâ”€â”€ extract/            # ğŸ“¥ MÃ³dulos para extrair dados das fontes.
â”‚   â”‚   â”œâ”€â”€ __init__.py         # <-- Transforma 'extract' em um pacote Python.
â”‚   â”‚   â””â”€â”€ from_csv.py
â”‚   â”œâ”€â”€ transform/          # ğŸ“¥ MÃ³dulos para transformaÃ§Ãµes leves nos dados das fontes.
â”‚   â”‚   â”œâ”€â”€ __init__.py         # <-- Transforma 'transform' em um pacote Python.
â”‚   â”‚   â”œâ”€â”€ clean_opendatasus.py
â”‚   â”‚   â””â”€â”€ clean_monito_ar.py
â”‚   â”œâ”€â”€ load/               # ğŸ“¤ MÃ³dulo para carregar os dados na camada 'bronze' do DW.
â”‚   â”‚   â”œâ”€â”€ __init__.py         # <-- Transforma 'load' em um pacote Python.
â”‚   â”‚   â””â”€â”€ to_postgres.py
â”‚   â”œâ”€â”€ __init__.py         # <-- Transforma 'src' em um pacote Python.
â”‚   â””â”€â”€ main.py             # ğŸš€ O orquestrador que chama E, L e a etapa de TransformaÃ§Ã£o (dbt).
â”‚
â”œâ”€â”€ tests/                  # âœ… Pasta para os testes unitÃ¡rios do seu cÃ³digo Python (Pytest).
â”‚   â”œâ”€â”€ test_extract.py
â”‚   â””â”€â”€ test_load.py
â””â”€â”€ uv.lock                 # ğŸ”’ Garante que todos usem as mesmas versÃµes das bibliotecas.

```

## Modelagem dos dados

![Fluxo dos dados](./assets/data-architecture.png)

## ğŸš€ Como Executar o Projeto

Siga os passos abaixo para configurar e rodar o ambiente de desenvolvimento localmente.

### PrÃ©-requisitos

-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/products/docker-desktop/)
-   [Python 3.12+](https://www.python.org/)
-   [uv](https://github.com/astral-sh/uv)

### InstalaÃ§Ã£o

1.  **Clone o repositÃ³rio:**

    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```

2.  **Configure as variÃ¡veis de ambiente:**
    Copie o arquivo de exemplo `.env.example` para um novo arquivo chamado `.env` e preencha com as credenciais do seu banco de dados.

    ```bash
    cp .env.example .env
    ```

3.  **Instale as dependÃªncias do projeto:**

    ```bash
    uv sync
    ```

4.  **Ative o ambiente virtual Python:**

    ```bash
    source .venv/bin/activate  # No Windows: .venv\Scripts\activate
    ```

5.  **Inicie o banco de dados com Docker:**
    Este comando irÃ¡ criar e iniciar o container do PostgreSQL em segundo plano.

    ```bash
    docker compose up -d # ou para versÃµes antigas docker-compose up -d
    ```

6.  **Para utilizar o dbt:**
    Crie um arquivo chamado profiles.yml dentro da pasta `/home/{seu_usuario}/.dbt/`.
    OBS: Pode criar a pasta caso nÃ£o exista.
    No Windows: `C:\Users\{seu_usuario}\.dbt`.

    ```yml
    postgres_dw:
        outputs:
            dev:
                # MESMAS INFORMAÃ‡Ã•ES DA .env
                dbname: your_database_name
                host: localhost
                pass: database_password
                port: 5432
                schema: public
                threads: 4
                type: postgres
                user: postgres
        target: dev
    ```

    Entre na pasta do projeto dbt.

    ```bash
    cd postgres_dw
    ```

    Instala as dependÃªncias do dbt.

    ```bash
    dbt deps
    ```

    Cria as tabelas com base nos CSVs do diretÃ³rio `postgres_dw/seeds`.

    ```bash
    dbt seed
    ```

    Teste o dbt

    ```bash
    dbt debug --connection
    ```

### UtilizaÃ§Ã£o

-   **Extraia os arquivos `*.zip` dentro da pasta `data`:**

-   **Para executar o a pipeline de extraÃ§Ã£o, carregamento e transformaÃ§Ã£o dos dados:**
    Dentro da sessÃ£o do ambiente virtual no terminal.

    ```bash
    python3 -m src.main # No Windows: python -m src.main
    ```

-   **Para anÃ¡lise exploratÃ³ria:**
    Inicie o Jupyter Lab para interagir com os notebooks de anÃ¡lise.

    ```bash
    jupyter lab
    ```

-   **Para visualizar o dashboard:**
    Execute a aplicaÃ§Ã£o Streamlit. O dashboard serÃ¡ aberto automaticamente no seu navegador.

    ```bash
    python3 -m streamlit run streamlit.app # No Windows: python -m streamlit run streamlit.app
    ```

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.
