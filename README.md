# Qualidade do Ar em Alguns Estados Brasileiros

![Status do Projeto](https://img.shields.io/badge/Status-Em%20Desenvolvimento-blue)
![Python](https://img.shields.io/badge/Python-3.12%2B-blue?logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue?logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Ativo-blue?logo=docker&logoColor=white)
![LicenÃ§a](https://img.shields.io/badge/License-MIT-green)

## ğŸ¯ Sobre o Projeto

Este projeto nasceu da necessidade de demonstrar, com dados concretos, a correlaÃ§Ã£o entre a poluiÃ§Ã£o do ar em centros urbanos e a incidÃªncia de doenÃ§as respiratÃ³rias na populaÃ§Ã£o. Como consultora ambiental, o objetivo Ã© transformar dados brutos em visualizaÃ§Ãµes claras e impactantes, que possam ser utilizadas em campanhas de conscientizaÃ§Ã£o e na formulaÃ§Ã£o de polÃ­ticas pÃºblicas.

A anÃ¡lise cruza informaÃ§Ãµes histÃ³ricas sobre a **qualidade do ar**, obtidas atravÃ©s de fontes como o sistema **MonitorAr**, com dados de internaÃ§Ãµes e procedimentos relacionados a doenÃ§as respiratÃ³rias, disponibilizados pelo **DATASUS**.

## âœ¨ Objetivos Principais

-   **Coletar e Consolidar:** Agregar dados de diferentes fontes em um banco de dados estruturado e confiÃ¡vel.
-   **Analisar:** Identificar tendÃªncias, padrÃµes e correlaÃ§Ãµes estatÃ­sticas entre os nÃ­veis de poluentes e os registros de saÃºde.
-   **Visualizar:** Criar grÃ¡ficos e mapas interativos que facilitem a compreensÃ£o dos resultados por um pÃºblico nÃ£o tÃ©cnico.
-   **Disponibilizar:** Apresentar os _insights_ em um dashboard interativo, permitindo a exploraÃ§Ã£o dos dados por capital e por perÃ­odo.

## ğŸ”— Links importantes relacionados as APIs/CSVs utilizados

-   [MonitorAr](https://dados.gov.br/dados/conjuntos-dados/ar-puro-monitorar)
-   [openDataSUS](https://opendatasus.saude.gov.br/dataset/srag-2021-a-2024)

## ğŸ› ï¸ Tecnologias Utilizadas

A arquitetura do projeto foi pensada para ser robusta, escalÃ¡vel e reprodutÃ­vel, utilizando as seguintes tecnologias:

| Tecnologia         | VersÃ£o/DescriÃ§Ã£o | PropÃ³sito na SoluÃ§Ã£o                                                      |
| :----------------- | :--------------- | :------------------------------------------------------------------------ |
| **PostgreSQL**     | `16-alpine`      | Banco de dados relacional para armazenamento seguro e estruturado.        |
| **Docker**         | `latest`         | ContainerizaÃ§Ã£o do banco de dados para garantir um ambiente consistente.  |
| **Python**         | `>=3.12`         | Linguagem principal para anÃ¡lise, processamento e visualizaÃ§Ã£o.           |
| **Jupyter**        | `>=1.1.1`        | AnÃ¡lise exploratÃ³ria de dados (EDA) e prototipagem de modelos.            |
| **Pandas**         | `>=2.3.1`        | ManipulaÃ§Ã£o, limpeza e estruturaÃ§Ã£o dos dados.                            |
| **NumPy**          | `>=2.3.1`        | OperaÃ§Ãµes numÃ©ricas e cÃ¡lculos cientÃ­ficos.                               |
| **Requests**       | `>=2.32.4`       | RealizaÃ§Ã£o de requisiÃ§Ãµes HTTP para coleta de dados de APIs externas.     |
| **psycopg-binary** | `>=3.2.9`        | Conector para comunicaÃ§Ã£o entre a aplicaÃ§Ã£o Python e o PostgreSQL.        |
| **dbt-postgres**   | `>=1.9.0`        | Ferramenta para transformaÃ§Ã£o de dados (ELT) no data warehouse.           |
| **Matplotlib**     | `>=3.10.3`       | CriaÃ§Ã£o de grÃ¡ficos estÃ¡ticos e customizados.                             |
| **Seaborn**        | `>=0.13.2`       | CriaÃ§Ã£o de grÃ¡ficos estatÃ­sticos e visualmente atraentes.                 |
| **Scikit-learn**   | `>=1.7.0`        | Modelagem estatÃ­stica e aplicaÃ§Ã£o de algoritmos de Machine Learning.      |
| **Streamlit**      | `>=1.46.1`       | ConstruÃ§Ã£o e deploy do dashboard interativo.                              |
| **Pytest**         | `>=8.4.1`        | Testes automatizados para garantir a qualidade e a integridade do cÃ³digo. |
| **python-dotenv**  | `>=1.1.1`        | Gerenciamento de variÃ¡veis de ambiente de forma segura.                   |

## ğŸ“‚ Estrutura do Projeto

**EM PROGRESSO**

```
.
â”œâ”€â”€ docker-compose.yml      # ğŸ³ Define e gerencia o serviÃ§o do banco de dados PostgreSQL.
â”‚
â”œâ”€â”€ notebooks/              # ğŸ““ Ambiente para anÃ¡lise de dados exploratÃ³ria (EDA) e experimentaÃ§Ã£o.
â”‚   â””â”€â”€ 00_exemplo.ipynb
â”‚
â”œâ”€â”€ postgres_dw/            # ğŸ˜ O DIRETÃ“RIO RAIZ DO SEU PROJETO DBT. Ã‰ aqui que o dbt vai operar.
â”‚   â”œâ”€â”€ analyses/           # <-- Para anÃ¡lises SQL que nÃ£o se tornam tabelas ou views (consultas ad-hoc).
â”‚   â”œâ”€â”€ dbt_project.yml     # <-- Configura o projeto, perfil e caminhos.
â”‚   â”œâ”€â”€ logs/               # <-- Pasta padrÃ£o onde o dbt salva os logs de execuÃ§Ã£o detalhados.
â”‚   â”‚   â””â”€â”€ dbt.log
â”‚   â”œâ”€â”€ macros/             # <-- Para criar funÃ§Ãµes reutilizÃ¡veis em Jinja/SQL.
â”‚   â”œâ”€â”€ models/             # âœ¨ A PASTA OFICIAL para seus modelos SQL de transformaÃ§Ã£o (staging, core, marts).
â”‚   â”‚   â”œâ”€â”€ staging/            # ğŸ§¼ Camada 1: Limpeza, tipagem e renomeaÃ§Ã£o (1:1 com a fonte)
â”‚   â”‚   â”‚   â””â”€â”€ stg_csv__exemplo.sql
â”‚   â”‚   â”œâ”€â”€ core/               # ğŸ’ Camada 2: O Star Schema (tabelas Fatos e DimensÃµes)
â”‚   â”‚   â”‚   â”œâ”€â”€ dim_exemplo.sql
â”‚   â”‚   â”‚   â””â”€â”€ fatos_exemplo.sql
â”‚   â”‚   â””â”€â”€ marts/              # ğŸ“ˆ Camada 3: Data Marts (visÃµes de negÃ³cio agregadas)
â”‚   â”‚       â””â”€â”€ mart_exemplo.sql
â”‚   â”œâ”€â”€ seeds/              # <-- Para carregar pequenos arquivos CSV no seu DW (ex: uma tabela de mapeamento de estados).
â”‚   â”œâ”€â”€ snapshots/          # <-- Para capturar mudanÃ§as em dados ao longo do tempo (SCD - Slowly Changing Dimensions).
â”‚   â”œâ”€â”€ target/             # ğŸ¯ Gerado pelo dbt.
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ tests/              # <-- Para testes de dados customizados do dbt.
â”‚
â”œâ”€â”€ pyproject.toml          # ğŸ Define as dependÃªncias do projeto Python para o 'uv'.
â”œâ”€â”€ README.md               # ğŸ“– A documentaÃ§Ã£o principal do seu projeto.
â”œâ”€â”€ src/                    # ğŸ‘¨â€ğŸ’» CÃ³digo-fonte Python para as etapas de ExtraÃ§Ã£o (E) e Carga (L).
â”‚   â”œâ”€â”€ extract/            # ğŸ“¥ MÃ³dulos para extrair dados das fontes.
â”‚   â”‚   â”œâ”€â”€ from_api_opendatasus.py
â”‚   â”‚   â””â”€â”€ from_csv.py
â”‚   â”œâ”€â”€ __init__.py         # <-- Transforma 'src' em um pacote Python.
â”‚   â”œâ”€â”€ load/               # ğŸ“¤ MÃ³dulo para carregar os dados na camada 'raw' do DW.
â”‚   â”‚   â””â”€â”€ to_postgres.py
â”‚   â””â”€â”€ main.py             # ğŸš€ O orquestrador que chama E, L e a etapa de TransformaÃ§Ã£o (dbt).
â”‚
â”œâ”€â”€ tests/                  # âœ… Pasta para os testes unitÃ¡rios do seu cÃ³digo Python (Pytest).
â”‚   â”œâ”€â”€ test_extract.py
â”‚   â””â”€â”€ test_load.py
â””â”€â”€ uv.lock                 # ğŸ”’ Garante que todos na equipe usem as mesmas versÃµes das bibliotecas.

```

## ğŸš€ Como Executar o Projeto

Siga os passos abaixo para configurar e rodar o ambiente de desenvolvimento localmente.

### PrÃ©-requisitos

-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/products/docker-desktop/)
-   [Python 3.12+](https://www.python.org/)
-   [uv](https://github.com/astral-sh/uv)

### InstalaÃ§Ã£o

1.  **Clone o repositÃ³rio:**

    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```

2.  **Configure as variÃ¡veis de ambiente:**
    Copie o arquivo de exemplo `.env.example` para um novo arquivo chamado `.env` e preencha com as credenciais do seu banco de dados.

    ```bash
    cp .env.example .env
    ```

3.  **Instale as dependÃªncias do projeto:**

    ```bash
    uv sync
    ```

4.  **Ative um ambiente virtual Python:**

    ```bash
    source .venv/bin/activate  # No Windows: .venv\bin\activate.bat
    ```

5.  **Inicie o banco de dados com Docker:**
    Este comando irÃ¡ criar e iniciar o container do PostgreSQL em segundo plano.

    ```bash
    docker-compose up -d
    ```

6.  **Para utilizar o dbt:**
    Teste o dbt
    ```bash
    dbt debug --project-dir ./postgres_dw
    ```

### UtilizaÃ§Ã£o

-   **Para anÃ¡lise exploratÃ³ria:**
    Inicie o Jupyter Lab para interagir com os notebooks de anÃ¡lise.

    ```bash
    jupyter lab
    ```

-   **Para visualizar o dashboard:**
    Execute a aplicaÃ§Ã£o Streamlit. O dashboard serÃ¡ aberto automaticamente no seu navegador.
    ```bash
    streamlit run src/app.py
    ```

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.
